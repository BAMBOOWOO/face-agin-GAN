{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31731,"status":"ok","timestamp":1679361896419,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"nvH5_QYx5LMb","outputId":"12e7ae1f-d878-40c8-8b4e-9ae1bb19507c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from google.colab import auth \n","auth.authenticate_user()\n","\n","\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RbOJQ7IDjDW"},"outputs":[],"source":["!unzip \"/content/drive/MyDrive/train.zip\" -d \"/content/sample_data\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YH8wCxHBe0JJ"},"outputs":[],"source":["!unzip '/content/drive/MyDrive/testdata.zip' -d \"/content/sample_data\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":5025,"status":"ok","timestamp":1685935011828,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"ahrmenlv5eb-","outputId":"44df3df4-d63a-43c0-e076-573a78e20501"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'labels = pd.read_csv(root/\\'train_label.txt\\', header=None, sep=\"\\t\")///'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch \n","import torchvision\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import random\n","import cv2\n","import os\n","import math\n","import time\n","from skimage import io\n","from torchvision.transforms import ToTensor\n","from torchvision.utils import make_grid\n","import torchvision.utils as vutils\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data import random_split\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset \n","from pathlib import Path\n","from PIL import Image\n","import torch.autograd as autograd\n","import pickle as pkl\n","import argparse\n","import logging\n","from tqdm import tqdm\n","from random import shuffle\n","import torch.utils.data\n","from torch.nn.parameter import Parameter\n","from torch.nn.functional import pad\n","from torch.nn.modules import Module\n","from torch.nn.modules.utils import _single, _pair, _triple\n","from torchvision.utils import save_image\n","device = torch.device(\"cuda\")\n","\"\"\"root = Path('/content/sample_data/train')\"\"\"\n","\"\"\"labels = pd.read_csv(root/'train_label.txt', header=None, sep=\"\\t\")///\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6newJGY66f9"},"outputs":[],"source":["source_img = []\n","with open(os.path.join(root, 'sourcelabel.txt'), 'r') as f:\n","    lines = f.readlines()\n","    lines = [line.strip() for line in lines]\n","shuffle(lines)\n","for l in lines:\n","    items = l.split()\n","    source_img.append(items[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PME10q-4NE7R"},"outputs":[],"source":["def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ts-doC9sVpgc"},"outputs":[],"source":["class CGAN(Dataset):\n","    def __init__(self, root_dir, labels, source, transfrom=None) -> None:\n","        super().__init__()\n","        self.root_dir = root_dir\n","        self.labels = labels\n","        self.source = source\n","        self.transform = transfrom\n","    def __len__(self):\n","        return self.labels.shape[0] \n","    def __getitem__(self, index):\n","        labels = self.labels.iloc[index, 1]\n","        img_name = os.path.join(self.root_dir, self.labels.iloc[index, 0]) \n","        source = os.path.join(self.root_dir, self.source[index])\n","        image = io.imread(img_name)\n","        source_image = io.imread(source)\n","        image = Image.fromarray(image)\n","        source_image =  Image.fromarray(source_image)\n","        source_image227 = source_image.resize((227, 227))\n","        source_image128 = source_image.resize((128, 128))\n","        if self.transform:\n","            simage227 = self.transform(source_image227)\n","            simage128 = self.transform(source_image128)\n","            image = self.transform(image)\n","        return  simage227, simage128, image, labels\n","class CGANtest(Dataset):\n","    def __init__(self, root_dir, labels, transform=None) -> None:\n","        super().__init__()\n","        self.root_dir = root_dir\n","        self.labels = labels\n","        self.transform = transform\n","    def __len__(self):\n","        return self.labels.shape[0] \n","    def __getitem__(self, index):\n","        labels = self.labels.iloc[index, 1]\n","        labels \n","        img_name = os.path.join(self.root_dir, self.labels.iloc[index, 0])\n","        image = io.imread(img_name)\n","        pimage = Image.fromarray(image)\n","        if self.transform:\n","            image = self.transform(pimage)\n","        return image, labels\n","\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":169,"status":"ok","timestamp":1685935346644,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"No7qOkMMA-4i"},"outputs":[],"source":["bins = [19, 29, 39, 49, 59]\n","\n","def one_hot_classify(x, bins):\n","    x = x.to(\"cpu\").numpy()\n","    idxs = np.digitize(x, bins, right=True)\n","    idxs = idxs.reshape(-1,1)\n","    idxs = torch.from_numpy(idxs)\n","    idxs = idxs.squeeze()\n","    return idxs\n","\n","def one_hot_gan(x, bins):\n","    '''\n","    Convert tensor x to one-hot tensor\n","    '''\n","    x = x.to(\"cpu\").numpy()\n","    idxs = np.digitize(x, bins, right=True)\n","    idxs = idxs.reshape(-1,1)\n","    z = torch.zeros(len(x), len(bins)+1).scatter_(1, torch.tensor(idxs), 1)\n","    return z"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685935680616,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"qTwAkgRyjuls","outputId":"4904964b-b46d-4a36-ac75-1ece1af035a8"},"outputs":[{"data":{"text/plain":["torch.Size([1, 6])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["V_data = [70]\n","V = torch.tensor(V_data)\n","\n","b = one_hot_gan(V, bins)\n","b.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4_9AHR04BBNA"},"outputs":[],"source":["def real_loss(D_out, smooth=False):\n","    batch_size = D_out.size(0)\n","    # label smoothing\n","    if smooth:\n","        # smooth, real labels = 0.9\n","        labels = torch.ones(batch_size)*0.9\n","    else:\n","        labels = torch.ones(batch_size) # real labels = 1\n","    # move labels to GPU if available     \n","    labels = labels.to(device)\n","    # binary cross entropy with logits loss\n","    criterion = nn.BCEWithLogitsLoss()\n","    # calculate loss\n","    loss = criterion(D_out, labels)  \n","    return loss\n","\n","def fake_loss(D_out):\n","    batch_size = D_out.size(0)\n","    labels = torch.zeros(batch_size) # fake labels = 0\n","    labels = labels.to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    # calculate loss\n","    loss = criterion(D_out, labels)\n","    return loss\n","\n","def accuracy(outputs, labels):\n","    outputs = torch.max(outputs, dim=1)[1]\n","    return torch.tensor(torch.sum(outputs == labels).item() / len(outputs))\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch\n","        labels = one_hot_classify(labels, bins).to(device)\n","        out = self(images)[0]\n","                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch  \n","        out = self(images)[0]    \n","       \n","        labels = one_hot_classify(labels, bins).to(device)\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)  # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","def check_dir(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXLtmTMcBEFw"},"outputs":[],"source":["class Reverse_zero_center(object):\n","    def __init__(self):\n","        pass\n","    def __call__(self,t_img):\n","        t_img=t_img/2+0.5\n","        return t_img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9M__f9KuBHxP"},"outputs":[],"source":["def conv_block(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n","              nn.BatchNorm2d(out_channels), \n","              nn.ReLU(inplace=True)]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","\n","class ResnetClassifier(ImageClassificationBase):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","        \n","        self.conv1 = conv_block(in_channels, 64, pool=True)\n","        self.conv2 = conv_block(64, 128, pool=True)\n","        self.conv3 = conv_block(128, 256, pool=True)\n","        self.res1 = nn.Sequential(conv_block(256, 256), conv_block(256, 256))\n","        \n","        self.conv4 = conv_block(256, 512, pool=True)\n","        self.conv5 = conv_block(512, 1024, pool=True)\n","        self.res2 = nn.Sequential(conv_block(1024, 1024), conv_block(1024, 1024))\n","        \n","        self.classifier = nn.Sequential(nn.MaxPool2d(7), \n","                                        nn.Flatten(), \n","                                        nn.Dropout(0.2),\n","                                        nn.Linear(1024, num_classes))\n","        \n","    def forward(self, xb):\n","        \n","        out = self.conv1(xb)\n","        out = self.conv2(out)\n","        out = self.conv3(out)\n","        out = self.res1(out) + out\n","        out = self.conv4(out)\n","        out = self.conv5(out)\n","        out6 = self.res2(out) + out\n","        out = self.classifier(out6)\n","    \n","        return [out, out6]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LXNZPqkED-x"},"outputs":[],"source":["def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","class BasicBlock(nn.Module):\n","\n","    def __init__(self, inplanes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += residual\n","        return out\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.conv1 = nn.Conv2d(9, 32, kernel_size=7, stride=1, padding=3)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n","        self.conv4 = nn.Conv2d(32, 3, kernel_size=7, stride=1, padding=3)\n","        self.bn1 = nn.BatchNorm2d(32, eps=0.001, track_running_stats=True)\n","        self.bn2 = nn.BatchNorm2d(64, eps=0.001, track_running_stats=True)\n","        self.bn3 = nn.BatchNorm2d(128, eps=0.001, track_running_stats=True)\n","        self.bn4 = nn.BatchNorm2d(64, eps=0.001, track_running_stats=True)\n","        self.bn5 = nn.BatchNorm2d(32, eps=0.001, track_running_stats=True)\n","        self.repeat_blocks=self._make_repeat_blocks(BasicBlock(128,128),6)\n","        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1)\n","        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=0,output_padding=1)\n","        self.relu=nn.ReLU()\n","        self.tanh=nn.Tanh()\n","\n","    def _make_repeat_blocks(self,block,repeat_times):\n","        layers=[]\n","        for i in range(repeat_times):\n","            layers.append(block)\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x,condition=None):\n","        if condition is not None:\n","            x=torch.cat((x,condition),1)\n","\n","        x = self.relu(self.bn1(self.conv1(x)))\n","        x = self.relu(self.bn2(self.conv2(x)))\n","        x = self.relu(self.bn3(self.conv3(x)))\n","        x = self.repeat_blocks(x)\n","        x = self.deconv1(x)\n","        x = self.relu(self.bn4(x))\n","        x = self.deconv2(x)\n","        x = self.relu(self.bn5(x))\n","        x = self.tanh(self.conv4(x))\n","        return x\n","\n","\n","def conv(in_channels, out_channels, kernel_size=4, stride=2, padding=1, batch_norm=True):\n","    layers = []\n","    conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n","    layers.append(conv_layer)\n","    \n","    if batch_norm:\n","        bn = nn.BatchNorm2d(out_channels)\n","        layers.append(bn)\n","        \n","    return nn.Sequential(*layers)\n","\n","class Discriminator(nn.Module):\n","    \n","    def __init__(self, y_size, conv_dim=64):\n","        '''\n","        Initialize the Discriminator Module\n","        :param conv_dim: The depth of the first convolutional layer\n","        :param y_size: The number of conditions \n","        '''\n","        super(Discriminator, self).__init__()\n","        self.conv_dim = conv_dim\n","        self.y_size = y_size\n","        self.conv1 = conv(3, conv_dim, 4, batch_norm=False)\n","        self.conv2 = conv(conv_dim+y_size, conv_dim * 2, 4)\n","        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n","        self.conv4 = conv(conv_dim*4, conv_dim*8, 4)\n","        self.conv5 = conv(conv_dim*8, conv_dim*10, 4)\n","        self.conv6 = conv(conv_dim*10, 1, 4, 1, 0, batch_norm=False)\n","            \n","    def forward(self, x, y):\n","        '''\n","        Forward propagation of the neural network\n","        :param x: The input scaled image x\n","        :param y: One-hot encoding condition tensor y (N,y_size)\n","        :return: Discriminator logits; the output of the neural network\n","        '''\n","        x = F.leaky_relu(self.conv1(x))\n","        y = y.view(-1,y.size()[-1],1,1)\n","        y = y.expand(-1,-1,x.size()[-2], x.size()[-1])\n","        x = torch.cat([x, y], 1)\n","        x = F.leaky_relu(self.conv2(x))\n","        x = F.dropout2d(x, 0.4)\n","        x = F.leaky_relu(self.conv3(x))\n","        x = F.dropout2d(x, 0.4)\n","        x = F.leaky_relu(self.conv4(x))\n","        x = F.dropout2d(x, 0.4)\n","        x = F.leaky_relu(self.conv5(x))\n","        x = F.dropout2d(x, 0.4)\n","        x = self.conv6(x)\n","        x2 = x.squeeze()\n","        return x2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heY7QKHKEIJZ"},"outputs":[],"source":["class CGANs:\n","    def __init__(self,lr=0.01, gan_loss_weight=75, feature_loss_weight=0.5e-4, age_loss_weight=30):\n","        self.d_lr=lr\n","        self.g_lr=lr\n","        self.D = Discriminator(6, 64).to(device)\n","        self.G = Generator().to(device)\n","        self.ageclassifier = ResnetClassifier(3, 6).to(device)\n","        checkpoint = torch.load('/content/drive/MyDrive/pretrainresnet.pth.tar')\n","        epoch = checkpoint['epoch']\n","        print(epoch)\n","        self.ageclassifier.load_state_dict(checkpoint['modelstate'])\n","        self.ageclassifier.eval()\n","        self.CEcriterion = nn.CrossEntropyLoss().to(device)\n","        self.MSEcriterion = nn.MSELoss().to(device)\n","        self.gan_loss_weight=gan_loss_weight\n","        self.feature_loss_weight = feature_loss_weight\n","        self.age_loss_weight=age_loss_weight\n","        self.d_optimizer = optim.Adam(self.D.parameters(), self.d_lr, betas=(0.5,0.999))\n","        self.g_optimizer = optim.Adam(self.G.parameters(), self.g_lr, betas=(0.5,0.999))\n","    def save_model(self, path):\n","        torch.save({\n","            'epoch' : epoch,\n","            'D_state_dict': self.D.state_dict(),\n","            'G_state_dict': self.G.state_dict(),\n","            'optimizerD_state_dict': self.d_optimizer.state_dict(),\n","            'optimizerG_state_dict': self.g_optimizer.state_dict(),\n","            }, path)\n","    def load_generator_state_dict(self,state_dict):\n","        pretrained_dict = state_dict\n","        # step2: get model state_dict\n","        model_dict = self.G.state_dict()\n","        # step3: remove pretrained_dict params which is not in model_dict\n","        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n","        # step4: update model_dict using pretrained_dict\n","        model_dict.update(pretrained_dict)\n","        # step5: update model using model_dict\n","        self.G.load_state_dict(model_dict)\n","    def test_generate(self,source_img_128,condition):\n","        self.G.eval()\n","        with torch.no_grad():\n","            generate_image=self.G(source_img_128,condition)\n","        return generate_image\n","    def cuda(self):\n","        self.G = self.G.cuda()\n","    def train(self, source227img, source128img, true_images, age_labels):\n","            true_image = true_images.to(device)\n","            size128 = true_image.size(2)\n","            true_labels = one_hot_gan(age_labels, bins).to(device)\n","            age_labels_cf = one_hot_classify(age_labels, bins).to(device)\n","            true_labels128 = true_labels.view(-1,true_labels.size()[-1],1,1)\n","            true_labels128 = true_labels128.expand(-1,-1, size128, size128).to(device)\n","            flabel = age_labels + 20.\n","            flabel = one_hot_gan(flabel, bins)\n","            flabel = flabel.to(device) #need to convert to 128*128 for generator\n","\n","            ###################################gan_loss###############################        \n","            self.G_source = self.G(source128img, condition=true_labels128)\n","            D_real = self.D(true_image, true_labels) #discriminator give labels\n","            d_real_loss = real_loss(D_real)\n","            D_reak_fake = self.D(true_image, flabel)\n","            d_realfake_loss = fake_loss(D_reak_fake)\n","            D_fake_real = self.D(self.G_source, true_labels)\n","            d_fakereal_loss = fake_loss(D_fake_real)\n","            d_fakereal_lossforG = real_loss(D_fake_real)\n","\n","            self.d_loss=(1./2 * (d_real_loss + 1. / 2 * (d_realfake_loss + d_fakereal_loss))) * self.gan_loss_weight\n","            \n","            g_loss=(1./2*d_fakereal_lossforG)* self.gan_loss_weight\n","\n","            ################################feature_loss#############################\n","            sourceac = self.ageclassifier(source227img)\n","            source_feature = sourceac[1] \n","            generate_img227 = F.interpolate(self.G_source, (227, 227), mode=\"bilinear\", align_corners=True)\n","            transform = torchvision.transforms.Normalize((0.5),(0.5))\n","            generate_img227 = transform(generate_img227)\n","            generateac = self.ageclassifier(generate_img227)\n","            generate_feature = generateac[1]\n","            self.feature_loss = self.MSEcriterion(source_feature, generate_feature)\n","\n","             ################################age_cls_loss##############################\n","\n","            age_logit = self.ageclassifier(generate_img227)[0]\n","            self.age_loss = self.CEcriterion(age_logit,age_labels_cf)\n","\n","            self.g_loss= self.age_loss + g_loss + self.feature_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1679361979250,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"gOfX-Ex3ELFg","outputId":"84d0dc6c-e9b8-46a5-9484-ceccbd745526"},"outputs":[{"name":"stdout","output_type":"stream","text":["5000\n"]}],"source":["root2 = Path('/content/sample_data/testdata')\n","testlabels = pd.read_csv(root2/'test_desired_age.txt', header=None, sep=\"\\t\")\n","finaltransfrom = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","            ])\n","testtransform = transforms.Compose([\n","                   transforms.ToTensor(),\n","                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n","traindata = CGAN(root, labels, source_img, transfrom=finaltransfrom)\n","testdata = CGANtest(root2, testlabels, transform = testtransform)\n","print(len(testdata))\n","train_set, val_set = torch.utils.data.random_split(traindata, [54999, 10000])\n","trainLoad = DataLoader(train_set, batch_size=80, shuffle=True, num_workers=4, pin_memory=True)\n","valLoad = DataLoader(val_set, batch_size=80, shuffle=False, num_workers=4, pin_memory=True)\n","testLoad = DataLoader(testdata, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n","FtrainLoad = DeviceDataLoader(trainLoad, device)\n","FvalLoad = DeviceDataLoader(valLoad, device)\n","FtestLoad = DeviceDataLoader(testLoad, device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OH8PBXCxENRA"},"outputs":[],"source":["model = CGANs(lr=1e-4, gan_loss_weight=75., feature_loss_weight=0.5e-4, age_loss_weight=30.)\n","                  #,feature_extractor_path=args.feature_extractor_path)\n","checkpoint = torch.load('/content/drive/MyDrive/GANcheckpoint2.pth.tar')\n","epoch = checkpoint['epoch']\n","print(epoch)\n","model.D.load_state_dict(checkpoint[\"D_state_dict\"])\n","\n","model.d_optimizer.load_state_dict(checkpoint['optimizerD_state_dict'])\n","model.g_optimizer.load_state_dict(checkpoint['optimizerG_state_dict'])\n","model.D.train()\n","d_optim=model.d_optimizer\n","g_optim=model.g_optimizer\n","model.G.load_state_dict(checkpoint['G_state_dict'])\n","model.G.eval()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ktmAeIHxvze"},"outputs":[],"source":["for test_idx, (image, labels) in enumerate(FtestLoad):\n","                validationpath = '/content/drive/MyDrive/testimagefr'\n","                save_dir = os.path.join(validationpath)\n","                image = Variable(image).to(device)\n","                labels = Variable(labels)\n","                aclabel = one_hot_classify(labels, bins).float().to(device)\n","                label = one_hot_gan(labels, bins)\n","                label = label.view(-1,label.size()[-1],1,1)\n","                labels128 = label.expand(-1,-1, 128, 128).to(device)\n","                img = model.test_generate(image, labels128).to(device)\n","                save_image(Reverse_zero_center()(img),fp=os.path.join(save_dir,\"batch_%d.jpg\"%test_idx))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJvF7MqREPFz"},"outputs":[],"source":["epochs = 50\n","for epoch in range(epochs):\n","      for batch_i, (simage227, simage128, image, labels) in enumerate(FtrainLoad):\n","            running_d_loss = None\n","            running_g_loss = None\n","            source_img_227 = Variable(simage227).to(device)\n","            source_img_128 = Variable(simage128).to(device)\n","            true_label_img = Variable(image).to(device)\n","            true_label = Variable(labels).to(device)\n","\n","            #train discriminator\n","            for d_iter in range(1):\n","                #d_lr_scheduler.step()\n","                d_optim.zero_grad()\n","                model.train(\n","                    source227img = source_img_227,\n","                    source128img = source_img_128,\n","                    true_images = true_label_img,\n","                    age_labels = true_label\n","                )\n","                d_loss=model.d_loss\n","                running_d_loss=d_loss\n","                d_loss.backward()\n","                d_optim.step()\n","\n","            #train generator\n","            for g_iter in range(2):\n","                #g_lr_scheduler.step()\n","                g_optim.zero_grad()\n","                model.train(\n","                    source227img = source_img_227,\n","                    source128img = source_img_128,\n","                    true_images = true_label_img,\n","                    age_labels = true_label\n","                )\n","                g_loss = model.g_loss\n","                running_g_loss=g_loss\n","                g_loss.backward()\n","                g_optim.step()\n","            if batch_i % 500 == 0:\n","                # append discriminator loss and generator loss\n","                # print discriminator and generator loss\n","                print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n","                        epoch+1, epochs, running_d_loss.item(), running_g_loss.item()))\n","      if (epoch+1)%10==0:\n","            model.save_model('/content/drive/MyDrive/GANcheckpoint2.pth.tar')\n","            print('got checkpoint')\n","            validationpath = '/content/drive/MyDrive/validation_4'\n","            save_dir = os.path.join(validationpath, \"epoch_%d\" % epoch)\n","            check_dir(save_dir) \n","            for val_idx, (simage227, simage128, image, labels) in enumerate(FvalLoad):\n","                source_img_128 = Variable(simage128).to(device)\n","                save_image(Reverse_zero_center()(source_img_128),fp=os.path.join(save_dir,\"batch_%d_source.jpg\"%(val_idx)))\n","                agelist = [19, 29, 39, 49, 59, 69]       \n","                for age in range(6):\n","                    a = [agelist[age] for _ in range(80)]\n","                    a = np.array(a)\n","                    a = torch.from_numpy(a)\n","                    label = a.view(-1, 1)\n","                    label = one_hot_gan(label, bins)\n","                    label = label.view(-1,label.size()[-1],1,1)\n","                    labels128 = label.expand(-1,-1, 128, 128).to(device)\n","                    img = model.test_generate(source_img_128, labels128)\n","                    save_image(Reverse_zero_center()(img),fp=os.path.join(save_dir,\"batch_%d_age_group_%d.jpg\"%(val_idx,age)))\n","            print('validation image has been created!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1679311849953,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"JDVHTQeGVzId","outputId":"71fefe3d-7324-47ed-d3e0-4a316799afee"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'history = [evaluate(model, FvalLoad)]\\nhistory += fit2(epochs, max_lr, model, FtrainLoad, FvalLoad, \\n                             grad_clip=grad_clip, \\n                             weight_decay=weight_decay, \\n                             opt_func=opt_func)\\nplt.subplot(1, 2, 1)\\nplot_losses(history)\\nplt.subplot(1, 2, 2)\\nplot_accuracies(history)'"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["#for evaluate\n","import torch \n","import torchvision\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import random\n","import cv2\n","import os\n","import math\n","import time\n","from skimage import io\n","from torchvision.transforms import ToTensor\n","from torchvision.utils import make_grid\n","import torchvision.utils as vutils\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data import random_split\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset \n","from pathlib import Path\n","from PIL import Image\n","import torch.autograd as autograd\n","import pickle as pkl\n","device = torch.device(\"cuda\")\n","\n","bins = [19, 29, 39, 49, 59]\n","def one_hot(x, bins):\n","    '''\n","    Convert tensor x to one-hot tensor\n","    '''\n","    x = x.to(\"cpu\").numpy()\n","    idxs = np.digitize(x, bins, right=True)\n","    idxs = idxs.reshape(-1,1)\n","    idxs = torch.from_numpy(idxs)\n","    idxs = idxs.squeeze()\n","    return idxs\n","def accuracy(outputs, labels):\n","    outputs = torch.max(outputs, dim=1)[1]\n","    return torch.tensor(torch.sum(outputs == labels).item() / len(outputs))\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch\n","        labels = one_hot(labels, bins).to(device)\n","        out = self(images)[0]\n","                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch  \n","        out = self(images)[0]     \n","       \n","        labels = one_hot(labels, bins).to(device)\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)  # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","    \n","def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs')\n","def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs')\n","\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","class CGAN(Dataset):\n","    def __init__(self, root_dir, labels, transform=None) -> None:\n","        super().__init__()\n","        self.root_dir = root_dir\n","        self.labels = labels\n","        self.transform = transform\n","    def __len__(self):\n","        return self.labels.shape[0] \n","    def __getitem__(self, index):\n","        labels = self.labels.iloc[index, 1]\n","        labels \n","        img_name = os.path.join(self.root_dir, self.labels.iloc[index, 0])\n","        image = io.imread(img_name)\n","        pimage = Image.fromarray(image)\n","        if self.transform:\n","            image = self.transform(pimage)\n","        return image, labels\n","\n","\n","\n","\n","def conv_block(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n","              nn.BatchNorm2d(out_channels), \n","              nn.ReLU(inplace=True)]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","\n","class ResNet9(ImageClassificationBase):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","        \n","        self.conv1 = conv_block(in_channels, 64, pool=True)\n","        self.conv2 = conv_block(64, 128, pool=True)\n","        self.conv3 = conv_block(128, 256, pool=True)\n","        self.res1 = nn.Sequential(conv_block(256, 256), conv_block(256, 256))\n","        \n","        self.conv4 = conv_block(256, 512, pool=True)\n","        self.conv5 = conv_block(512, 1024, pool=True)\n","        self.res2 = nn.Sequential(conv_block(1024, 1024), conv_block(1024, 1024))\n","        \n","        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n","                                        nn.Flatten(), \n","                                        nn.Dropout(0.2),\n","                                        nn.Linear(1024, num_classes))\n","        \n","    def forward(self, xb):\n","        \n","        out = self.conv1(xb)\n","        out = self.conv2(out)\n","        out = self.conv3(out)\n","        out = self.res1(out) + out\n","        out = self.conv4(out)\n","        out = self.conv5(out)\n","        out6 = self.res2(out) + out\n","        out = self.classifier(out6)\n","    \n","        return [out, out6]\n","\n","def fit2(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay) #weight decay\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, # learnig rata scheduler\n","                                                steps_per_epoch=len(train_loader))\n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            if grad_clip:  # gradient clipping\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            sched.step()\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","        if (epoch+1)%10 == 0:\n","          torch.save({\n","             'epoch': epoch,\n","             'modelstate': model.state_dict(), \n","          },'/content/drive/MyDrive/pretrainresneteval.pth.tar')\n","    return history\n","\n","classifier = to_device(ResNet9(3, 6), device)\n","\n","epochs = 40\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam\n","\"\"\"history = [evaluate(model, FvalLoad)]\n","history += fit2(epochs, max_lr, model, FtrainLoad, FvalLoad, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","plt.subplot(1, 2, 1)\n","plot_losses(history)\n","plt.subplot(1, 2, 2)\n","plot_accuracies(history)\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xxNTsWpqjqF"},"outputs":[],"source":["checkpoint = torch.load('/content/drive/MyDrive/pretrainresneteval.pth.tar')\n","epoch = checkpoint['epoch']\n","\n","print(epoch)\n","\n","classifier.load_state_dict(checkpoint['modelstate'])\n","\n","classifier.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HurHOELysGS_"},"outputs":[],"source":["total = torch.tensor(0.).to(device)\n","acclist = []\n","total = torch.tensor([0]).float\n","for test_idx, (image, labels) in enumerate(FtestLoad):\n","                image = Variable(image).to(device)\n","                labels = Variable(labels)\n","                aclabel = one_hot_classify(labels, bins).float().to(device)\n","                label = one_hot_gan(labels, bins)\n","                label = label.view(-1,label.size()[-1],1,1)\n","                labels128 = label.expand(-1,-1, 128, 128).to(device)\n","                img = model.test_generate(image, labels128).to(device)\n","                outputs = classifier(img)[0].to(device)\n","                acc = accuracy(outputs, aclabel)\n","                total+=acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1679312486808,"user":{"displayName":"Bamboo Wu","userId":"05461943101653541272"},"user_tz":420},"id":"ceGkxpSozUGz","outputId":"e9e93ee2-9862-4d0a-d5e1-e654df4ca3ff"},"outputs":[{"data":{"text/plain":["tensor([0.2952])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["total/(test_idx+1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGbt0hSew6il"},"outputs":[],"source":["#age classifier for GAN\n","import torch \n","import torchvision\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import random\n","import cv2\n","import os\n","import math\n","import time\n","from skimage import io\n","from torchvision.transforms import ToTensor\n","from torchvision.utils import make_grid\n","import torchvision.utils as vutils\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data import random_split\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset \n","from pathlib import Path\n","from PIL import Image\n","import torch.autograd as autograd\n","import pickle as pkl\n","device = torch.device(\"cuda\")\n","root = Path('/content/sample_data/train')\n","\n","labels = pd.read_csv(root/'train_label.txt', header=None, sep=\"\\t\")\n","bins = [19, 29, 39, 49, 59]\n","def one_hot(x, bins):\n","    '''\n","    Convert tensor x to one-hot tensor\n","    '''\n","    x = x.to(\"cpu\").numpy()\n","    idxs = np.digitize(x, bins, right=True)\n","    idxs = idxs.reshape(-1,1)\n","    idxs = torch.from_numpy(idxs)\n","    idxs = idxs.squeeze()\n","    return idxs\n","def accuracy(outputs, labels):\n","    outputs = torch.max(outputs, dim=1)[1]\n","    return torch.tensor(torch.sum(outputs == labels).item() / len(outputs))\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch\n","        labels = one_hot(labels, bins).to(device)\n","        out = self(images)[0]\n","                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch  \n","        out = self(images)[0]     \n","       \n","        labels = one_hot(labels, bins).to(device)\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)  # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","    \n","def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs')\n","def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs')\n","\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","class CGAN(Dataset):\n","    def __init__(self, root_dir, labels, transform=None) -> None:\n","        super().__init__()\n","        self.root_dir = root_dir\n","        self.labels = labels\n","        self.transform = transform\n","    def __len__(self):\n","        return self.labels.shape[0] \n","    def __getitem__(self, index):\n","        labels = self.labels.iloc[index, 1]\n","        labels \n","        img_name = os.path.join(self.root_dir, self.labels.iloc[index, 0])\n","        image = io.imread(img_name)\n","        pimage = Image.fromarray(image)\n","        if self.transform:\n","            image = self.transform(pimage)\n","        return image, labels\n","\n","\n","\n","transform = transforms.Compose([\n","    transforms.Pad(4),\n","    transforms.CenterCrop(227),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                         ])\n","testtransform = transforms.Compose([transforms.CenterCrop(128),\n","                   transforms.ToTensor(),\n","                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n","traindata = CGAN(root, labels, transform=transform)\n","'''testdata = CGAN(root2, testlabels, transform = testtransform)'''\n","train_set, val_set = torch.utils.data.random_split(traindata, [54999, 10000])\n","trainLoad = DataLoader(train_set, batch_size=400, shuffle=True, num_workers=4, pin_memory=True)\n","val_load = DataLoader(val_set, batch_size=400, shuffle=False, num_workers=4, pin_memory=True)\n","'''testLoad = DataLoader(testdata, batch_size=500, shuffle=False, num_workers=4, pin_memory=True)'''\n","FtrainLoad = DeviceDataLoader(trainLoad, device)\n","FvalLoad = DeviceDataLoader(val_load, device)\n","'''FtestLoad = DeviceDataLoader(testLoad, device)'''\n","def conv_block(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n","              nn.BatchNorm2d(out_channels), \n","              nn.ReLU(inplace=True)]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","\n","class ResNet9(ImageClassificationBase):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","        \n","        self.conv1 = conv_block(in_channels, 64, pool=True)\n","        self.conv2 = conv_block(64, 128, pool=True)\n","        self.conv3 = conv_block(128, 256, pool=True)\n","        self.res1 = nn.Sequential(conv_block(256, 256), conv_block(256, 256))\n","        \n","        self.conv4 = conv_block(256, 512, pool=True)\n","        self.conv5 = conv_block(512, 1024, pool=True)\n","        self.res2 = nn.Sequential(conv_block(1024, 1024), conv_block(1024, 1024))\n","        \n","        self.classifier = nn.Sequential(nn.MaxPool2d(7), \n","                                        nn.Flatten(), \n","                                        nn.Dropout(0.2),\n","                                        nn.Linear(1024, num_classes))\n","        \n","    def forward(self, xb):\n","        \n","        out = self.conv1(xb)\n","        out = self.conv2(out)\n","        out = self.conv3(out)\n","        out = self.res1(out) + out\n","        out = self.conv4(out)\n","        out = self.conv5(out)\n","        out6 = self.res2(out) + out\n","        out = self.classifier(out6)\n","    \n","        return [out, out6]\n","\n","def fit2(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay) #weight decay\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, # learnig rata scheduler\n","                                                steps_per_epoch=len(train_loader))\n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            if grad_clip:  # gradient clipping\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            sched.step()\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","        if (epoch+1)%10 == 0:\n","          torch.save({\n","             'epoch': epoch,\n","             'modelstate': model.state_dict(), \n","          },'/content/drive/MyDrive/pretrainresnet.pth.tar')\n","    return history\n","\n","model = to_device(ResNet9(3, 6), device)\n","\n","epochs = 40\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam\n","\"\"\"history = [evaluate(model, FvalLoad)]\n","history += fit2(epochs, max_lr, model, FtrainLoad, FvalLoad, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)\n","plt.subplot(1, 2, 1)\n","plot_losses(history)\n","plt.subplot(1, 2, 2)\n","plot_accuracies(history)\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yuzVpkbEr07N"},"outputs":[],"source":["\n","checkpoint = torch.load('/content/drive/MyDrive/pretrainresnet.pth.tar')\n","epoch = checkpoint['epoch']\n","\n","print(epoch)\n","\n","model.load_state_dict(checkpoint['modelstate'])\n","\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrB2wn2GDRng"},"outputs":[],"source":["history = [evaluate(model, FtestLoad)]"]}],"metadata":{"colab":{"gpuClass":"premium","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
